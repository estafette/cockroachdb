apiVersion: v1
kind: Namespace
metadata:
  name: ${NAMESPACE}
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ${APP_NAME}
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}
    team: ${TEAM_NAME}
---
apiVersion: v1
kind: Service
metadata:
  # This service is meant to be used by clients of the database. It exposes a ClusterIP that will
  # automatically load balance connections to the different database pods.
  name: ${APP_NAME}-public
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}
    team: ${TEAM_NAME}
spec:
  ports:
  # The main port, served by gRPC, serves Postgres-flavor SQL, internode
  # traffic and the cli.
  - port: 26257
    targetPort: 26257
    name: grpc
  # The secondary port serves the UI as well as health and debug endpoints.
  - port: 8080
    targetPort: 8080
    name: http
  selector:
    app: ${APP_NAME}
---
apiVersion: v1
kind: Service
metadata:
  # This service only exists to create DNS entries for each pod in the stateful
  # set such that they can resolve each other's IP addresses. It does not
  # create a load-balanced ClusterIP and should not be used directly by clients
  # in most circumstances.
  name: ${APP_NAME}
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}
    team: ${TEAM_NAME}
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  ports:
  - port: 26257
    targetPort: 26257
    name: grpc
  - port: 8080
    targetPort: 8080
    name: http
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other CockroachDB pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  clusterIP: None
  selector:
    app: ${APP_NAME}
---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: ${APP_NAME}-budget
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}
    team: ${TEAM_NAME}
spec:
  selector:
    matchLabels:
      app: ${APP_NAME}
  maxUnavailable: 1
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: ${APP_NAME}
spec:
  serviceName: "${APP_NAME}"
  replicas: ${REPLICAS}
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: ${APP_NAME}
  template:
    metadata:
      labels:
        app: ${APP_NAME}
        team: ${TEAM_NAME}
      annotations:
        # Enable automatic monitoring of all instances when Prometheus is running in the cluster.
        prometheus.io/scrape: "true"
        prometheus.io/path: "/_status/vars"
        prometheus.io/port: "8080"
        prometheus.io/scheme: "http"
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - ${APP_NAME}
            topologyKey: kubernetes.io/hostname
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 10
            preference:
              matchExpressions:
              - key: cloud.google.com/gke-preemptible
                operator: In
                values:
                - "true"
      serviceAccountName: ${APP_NAME}
      # Init containers are run only once in the lifetime of a pod, before
      # it's started up for the first time. It has to exit successfully
      # before the pod's main containers are allowed to start.
      initContainers:
      # The init-certs container sends a certificate signing request to the
      # kubernetes cluster.
      # You can see pending requests using: kubectl get csr
      # CSRs can be approved using:         kubectl certificate approve <csr name>
      #
      # All addresses used to contact a node must be specified in the --addresses arg.
      #
      # In addition to the node certificate and key, the init-certs entrypoint will symlink
      # the cluster CA to the certs directory.
      - name: init-certs
        image: cockroachdb/cockroach-k8s-request-cert:0.4
        imagePullPolicy: IfNotPresent
        command:
          - /bin/ash
          - -ecx
          - >-
            /request-cert
            -namespace=${POD_NAMESPACE}
            -certs-dir=/cockroach-certs/
            -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            -type=node
            -addresses=localhost,127.0.0.1,$(hostname -f),$(hostname -f|cut -f 1-2 -d '.'),${APP_NAME}-public,${APP_NAME}-public.$(hostname -f|cut -f 3- -d '.')
        env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
          - name: certs
            mountPath: /cockroach-certs/
      containers:
      - name: ${APP_NAME}
        image: cockroachdb/cockroach:${COCKROACHDB_VERSION}
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST}
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT}
        env:
        - name: "COCKROACH_SKIP_ENABLING_DIAGNOSTIC_REPORTING"
          value: "true"
        - name: COCKROACH_CHANNEL
          value: kubernetes-insecure
        ports:
        - containerPort: 26257
          name: grpc
        - containerPort: 8080
          name: http
        volumeMounts:
        - name: ${APP_NAME}-datadir
          mountPath: /cockroach/cockroach-data
        - name: certs
          mountPath: /cockroach/cockroach-certs/
        args:
          - shell
          - -ecx
          # The use of qualified `hostname -f` is crucial:
          # Other nodes aren't able to look up the unqualified hostname.
          #
          # `--join` CLI flag is hardcoded to exactly 3 Pods, because:
          # 1. Having `--join` value depending on `statefulset.replicas`
          #    will trigger undesired restart of existing Pods when
          #    StatefulSet is scaled up/down. We want to scale without
          #    restarting existing Pods.
          # 2. At least one Pod in `--join` is enough to successfully
          #    join CockroachDB cluster and gossip with all other existing
          #    Pods, even if there are 3 or more Pods.
          # 3. It's harmless for `--join` to have 3 Pods even for 1-Pod
          #    clusters, while it gives us opportunity to scale up even if
          #    some Pods of existing cluster are down (for whatever reason).
          # See details explained here:
          # https://github.com/helm/charts/pull/18993#issuecomment-558795102
          - >-
            exec /cockroach/cockroach
            start --join=${APP_NAME}-0.${APP_NAME},${APP_NAME}-1.${APP_NAME},${APP_NAME}-2.${APP_NAME}${JOIN_REMOTE_HOSTS}
            --advertise-host=$(hostname -f)
            --logtostderr
            --insecure
            --http-host 0.0.0.0
            --cache=.35
            --max-sql-memory=.35
            --locality ${LOCALITY}
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /health?ready=1
            port: http
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 2
      # No pre-stop hook is required, a SIGTERM plus some time is all that's
      # needed for graceful shutdown of a node.
      terminationGracePeriodSeconds: 60
      volumes:
      - name: ${APP_NAME}-datadir
        persistentVolumeClaim:
          claimName: ${APP_NAME}-datadir
      - name: certs
        emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: ${APP_NAME}-datadir
      namespace: ${NAMESPACE}
      annotations:
        volume.beta.kubernetes.io/storage-class: ${STORAGE_CLASS}
    spec:
      accessModes:
        - "ReadWriteOnce"
      resources:
        requests:
          storage: ${PVC_SIZE}
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: ${APP_NAME}
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}
    team: ${TEAM_NAME}
  annotations:
    kubernetes.io/ingress.class: "gce"
    kubernetes.io/ingress.allow-http: "false"
    estafette.io/cloudflare-dns: "${ENABLE_CLOUDFLARE_DNS}"
    estafette.io/cloudflare-proxy: "true"
    estafette.io/cloudflare-hostnames: "${HOSTNAMES}"
spec:
  tls:
  - hosts:
    - ${HOSTNAMES}
    secretName: ${APP_NAME}-letsencrypt-certificate
  rules:
  - host: ${HOSTNAMES}
    http:
      paths:
      - path: /*
        backend:
          serviceName: ${APP_NAME}-admin
          servicePort: http
---
apiVersion: v1
kind: Secret
metadata:
  name: ${APP_NAME}-letsencrypt-certificate
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}
    team: ${TEAM_NAME}
  annotations:
    estafette.io/letsencrypt-certificate: "true"
    estafette.io/letsencrypt-certificate-hostnames: "${HOSTNAMES}"
---
apiVersion: v1
kind: Service
metadata:
  name: ${APP_NAME}-admin
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}-admin
    team: ${TEAM_NAME}
  annotations:
    prometheus.io/probe: "true"
    prometheus.io/probe-path: "/health"
    beta.cloud.google.com/backend-config: '{"default": "${APP_NAME}-admin"}'
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    targetPort: 8080
    protocol: TCP
  selector:
    app: ${APP_NAME}
---
apiVersion: cloud.google.com/v1beta1
kind: BackendConfig
metadata:
  name: ${APP_NAME}-admin
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}-admin
    team: ${TEAM_NAME}
spec:
  iap:
    enabled: true
    oauthclientCredentials:
      secretName: ${APP_NAME}-admin-iap-oauth-credentials
  timeoutSec: 120
---
apiVersion: v1
kind: Secret
metadata:
  name: ${APP_NAME}-admin-iap-oauth-credentials
  namespace: ${NAMESPACE}
  labels:
    app: ${APP_NAME}-admin
    team: ${TEAM_NAME}
type: Opaque
data:
  client_id: ${IAP_OAUTH_CLIENT_ID}
  client_secret: ${IAP_OAUTH_CLIENT_SECRET}